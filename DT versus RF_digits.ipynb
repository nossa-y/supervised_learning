{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%matplotlib inline\n",
    "import scipy\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color='green'>Troisième partie: Arbres de décision vs. Forêts aléatoires\n",
    "\n",
    "##   <font color='blue'>Etape 1. Visualiser la base de chiffres manuscrits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 2 3 4 5 6 7 8 9]\n",
      "['pixel_0_0', 'pixel_0_1', 'pixel_0_2', 'pixel_0_3', 'pixel_0_4', 'pixel_0_5', 'pixel_0_6', 'pixel_0_7', 'pixel_1_0', 'pixel_1_1', 'pixel_1_2', 'pixel_1_3', 'pixel_1_4', 'pixel_1_5', 'pixel_1_6', 'pixel_1_7', 'pixel_2_0', 'pixel_2_1', 'pixel_2_2', 'pixel_2_3', 'pixel_2_4', 'pixel_2_5', 'pixel_2_6', 'pixel_2_7', 'pixel_3_0', 'pixel_3_1', 'pixel_3_2', 'pixel_3_3', 'pixel_3_4', 'pixel_3_5', 'pixel_3_6', 'pixel_3_7', 'pixel_4_0', 'pixel_4_1', 'pixel_4_2', 'pixel_4_3', 'pixel_4_4', 'pixel_4_5', 'pixel_4_6', 'pixel_4_7', 'pixel_5_0', 'pixel_5_1', 'pixel_5_2', 'pixel_5_3', 'pixel_5_4', 'pixel_5_5', 'pixel_5_6', 'pixel_5_7', 'pixel_6_0', 'pixel_6_1', 'pixel_6_2', 'pixel_6_3', 'pixel_6_4', 'pixel_6_5', 'pixel_6_6', 'pixel_6_7', 'pixel_7_0', 'pixel_7_1', 'pixel_7_2', 'pixel_7_3', 'pixel_7_4', 'pixel_7_5', 'pixel_7_6', 'pixel_7_7']\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1600x600 with 10 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_samples: [178 182 177 183 181 182 181 179 174 180]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_digits\n",
    "\n",
    "# Load Iris dataset\n",
    "digits = load_digits()\n",
    "\n",
    "## print the label species(setosa, versicolor,virginica)\n",
    "print(digits.target_names)\n",
    "## print the names of the four features\n",
    "print(digits.feature_names)\n",
    "\n",
    "# Affichage des 10 premières images\n",
    "fig = plt.figure(figsize=(16,6))\n",
    "for i, digit in enumerate(digits.images[:10]):\n",
    "    fig.add_subplot(1,10,i+1)\n",
    "    plt.imshow(digit, cmap='binary')\n",
    "plt.show()\n",
    "\n",
    "print(\"n_samples: %s\" % np.bincount(digits.target))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1797, 64)\n"
     ]
    }
   ],
   "source": [
    "data = pd.DataFrame(digits.data)\n",
    "target = pd.Series(digits.target, name='target')\n",
    "df = pd.concat([data, target], axis=1)\n",
    "df.describe()\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Travail d'analyse\n",
    "- Déterminer les descripteurs, les classes et le nombre d'exemples par classe.\n",
    "- Donner un avis sur la qualité des données en comparant à la base MNIST exploitée pour le TP clustering."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##   <font color='blue'> Etape 2. Classification multi-classes avec un Arbres de Décision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy value: 100 %\n"
     ]
    }
   ],
   "source": [
    "from sklearn import tree\n",
    "\n",
    "#Accuracy of the model on the whole dataset\n",
    "X, y = digits.data, digits.target\n",
    "clf = tree.DecisionTreeClassifier()\n",
    "clf.fit(X, y)\n",
    "accuracy = clf.score(X,y)\n",
    "\n",
    "print(\"Accuracy value:\",\"%.0f\" %(100*accuracy),\"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Travail d'analyse\n",
    "- Expliquer la valeur de performance obtenue.\n",
    "\n",
    "### Dans ce qui suit, partager la base en deux sous-ensemble, apprentissage et test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy value: 82.76 %\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "# 90% of data in the test, 10% for the training\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5, random_state=0)\n",
    "\n",
    "clf = tree.DecisionTreeClassifier()\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "Z = clf.predict(X_test)\n",
    "accuracy = clf.score(X_test,y_test)\n",
    "print(\"Accuracy value:\",\"%.2f\" %(100*accuracy),\"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Travail d'analyse\n",
    "- Exécuter la fonction ci-dessus 10 fois. Discuter.\n",
    "- En appliquant 100 tirages aléatoires de l'ensemble d'apprentissage et de test, évaluer les performances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "82.425 %\n",
      "0.009\n"
     ]
    }
   ],
   "source": [
    "N = 100\n",
    "accuracies = []\n",
    "for i in range(N):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5, random_state=0)\n",
    "    clf = tree.DecisionTreeClassifier()\n",
    "    clf.fit(X_train, y_train)\n",
    "    Z = clf.predict(X_test)\n",
    "    accuracies.append(clf.score(X_test,y_test))\n",
    "    #print(accuracies[i])\n",
    "\n",
    "print(\"%.3f\" %(100*(np.mean(accuracies))),\"%\")\n",
    "print(\"%.3f\" %((np.std(accuracies))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##   <font color='blue'> Etape 3. Classification avec les Forêts Aléatoires\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest (300 trees) : 97.11 %\n",
      "Decision Tree : 82.76 %\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "clf = RandomForestClassifier(n_estimators=250)\n",
    "clf.fit(X_train, y_train)\n",
    "accuracy2 = clf.score(X_test,y_test)\n",
    "print(\"Random Forest (300 trees) : \"\"%.2f\" %(100*accuracy2),\"%\")\n",
    "\n",
    "clf = tree.DecisionTreeClassifier()\n",
    "clf.fit(X_train, y_train)\n",
    "accuracy1 = clf.score(X_test,y_test)\n",
    "print(\"Decision Tree : \"\"%.2f\" %(100*accuracy1),\"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.008"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean([0.008, 0.009, 0.007, 0.008, 0.008, 0.008, 0.008, 0.007, 0.009])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m     X_train, X_test, y_train, y_test \u001b[38;5;241m=\u001b[39m train_test_split(X, y, test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.5\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m      5\u001b[0m     clf \u001b[38;5;241m=\u001b[39m RandomForestClassifier(n_estimators\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m300\u001b[39m)\n\u001b[0;32m----> 6\u001b[0m     \u001b[43mclf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m     rf_accuracies\u001b[38;5;241m.\u001b[39mappend(clf\u001b[38;5;241m.\u001b[39mscore(X_test,y_test))\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%.3f\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m(\u001b[38;5;241m100\u001b[39m\u001b[38;5;241m*\u001b[39m(np\u001b[38;5;241m.\u001b[39mmean(rf_accuracies))),\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/sklearn/base.py:1351\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1344\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1346\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1347\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1348\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1349\u001b[0m     )\n\u001b[1;32m   1350\u001b[0m ):\n\u001b[0;32m-> 1351\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:489\u001b[0m, in \u001b[0;36mBaseForest.fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    478\u001b[0m trees \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    479\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_estimator(append\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, random_state\u001b[38;5;241m=\u001b[39mrandom_state)\n\u001b[1;32m    480\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_more_estimators)\n\u001b[1;32m    481\u001b[0m ]\n\u001b[1;32m    483\u001b[0m \u001b[38;5;66;03m# Parallel loop: we prefer the threading backend as the Cython code\u001b[39;00m\n\u001b[1;32m    484\u001b[0m \u001b[38;5;66;03m# for fitting the trees is internally releasing the Python GIL\u001b[39;00m\n\u001b[1;32m    485\u001b[0m \u001b[38;5;66;03m# making threading more efficient than multiprocessing in\u001b[39;00m\n\u001b[1;32m    486\u001b[0m \u001b[38;5;66;03m# that case. However, for joblib 0.12+ we respect any\u001b[39;00m\n\u001b[1;32m    487\u001b[0m \u001b[38;5;66;03m# parallel_backend contexts set at a higher level,\u001b[39;00m\n\u001b[1;32m    488\u001b[0m \u001b[38;5;66;03m# since correctness does not rely on using threads.\u001b[39;00m\n\u001b[0;32m--> 489\u001b[0m trees \u001b[38;5;241m=\u001b[39m \u001b[43mParallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    490\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    491\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    492\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprefer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mthreads\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    493\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    494\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_parallel_build_trees\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    495\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    496\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbootstrap\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    497\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    498\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    499\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    500\u001b[0m \u001b[43m        \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    501\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrees\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    502\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    503\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclass_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclass_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    504\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_samples_bootstrap\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_samples_bootstrap\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    505\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmissing_values_in_feature_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmissing_values_in_feature_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    506\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    507\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrees\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    508\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    510\u001b[0m \u001b[38;5;66;03m# Collect newly grown trees\u001b[39;00m\n\u001b[1;32m    511\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimators_\u001b[38;5;241m.\u001b[39mextend(trees)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/sklearn/utils/parallel.py:67\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     62\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[1;32m     63\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     64\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[1;32m     65\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[1;32m     66\u001b[0m )\n\u001b[0;32m---> 67\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/joblib/parallel.py:1863\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1861\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_sequential_output(iterable)\n\u001b[1;32m   1862\u001b[0m     \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[0;32m-> 1863\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(output)\n\u001b[1;32m   1865\u001b[0m \u001b[38;5;66;03m# Let's create an ID that uniquely identifies the current call. If the\u001b[39;00m\n\u001b[1;32m   1866\u001b[0m \u001b[38;5;66;03m# call is interrupted early and that the same instance is immediately\u001b[39;00m\n\u001b[1;32m   1867\u001b[0m \u001b[38;5;66;03m# re-used, this id will be used to prevent workers that were\u001b[39;00m\n\u001b[1;32m   1868\u001b[0m \u001b[38;5;66;03m# concurrently finalizing a task from the previous call to run the\u001b[39;00m\n\u001b[1;32m   1869\u001b[0m \u001b[38;5;66;03m# callback.\u001b[39;00m\n\u001b[1;32m   1870\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/joblib/parallel.py:1792\u001b[0m, in \u001b[0;36mParallel._get_sequential_output\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1790\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_batches \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   1791\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m-> 1792\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1793\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_completed_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   1794\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprint_progress()\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/sklearn/utils/parallel.py:129\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    127\u001b[0m     config \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m    128\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig):\n\u001b[0;32m--> 129\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:192\u001b[0m, in \u001b[0;36m_parallel_build_trees\u001b[0;34m(tree, bootstrap, X, y, sample_weight, tree_idx, n_trees, verbose, class_weight, n_samples_bootstrap, missing_values_in_feature_mask)\u001b[0m\n\u001b[1;32m    189\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m class_weight \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbalanced_subsample\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    190\u001b[0m         curr_sample_weight \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m=\u001b[39m compute_sample_weight(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbalanced\u001b[39m\u001b[38;5;124m\"\u001b[39m, y, indices\u001b[38;5;241m=\u001b[39mindices)\n\u001b[0;32m--> 192\u001b[0m     \u001b[43mtree\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    193\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    194\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    195\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcurr_sample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    196\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcheck_input\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    197\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmissing_values_in_feature_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmissing_values_in_feature_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    198\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    199\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    200\u001b[0m     tree\u001b[38;5;241m.\u001b[39m_fit(\n\u001b[1;32m    201\u001b[0m         X,\n\u001b[1;32m    202\u001b[0m         y,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    205\u001b[0m         missing_values_in_feature_mask\u001b[38;5;241m=\u001b[39mmissing_values_in_feature_mask,\n\u001b[1;32m    206\u001b[0m     )\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/sklearn/tree/_classes.py:305\u001b[0m, in \u001b[0;36mBaseDecisionTree._fit\u001b[0;34m(self, X, y, sample_weight, check_input, missing_values_in_feature_mask)\u001b[0m\n\u001b[1;32m    303\u001b[0m y_encoded \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros(y\u001b[38;5;241m.\u001b[39mshape, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mint\u001b[39m)\n\u001b[1;32m    304\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_outputs_):\n\u001b[0;32m--> 305\u001b[0m     classes_k, y_encoded[:, k] \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munique\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_inverse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    306\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_\u001b[38;5;241m.\u001b[39mappend(classes_k)\n\u001b[1;32m    307\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_classes_\u001b[38;5;241m.\u001b[39mappend(classes_k\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m])\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/numpy/lib/arraysetops.py:274\u001b[0m, in \u001b[0;36munique\u001b[0;34m(ar, return_index, return_inverse, return_counts, axis, equal_nan)\u001b[0m\n\u001b[1;32m    272\u001b[0m ar \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masanyarray(ar)\n\u001b[1;32m    273\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m axis \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 274\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[43m_unique1d\u001b[49m\u001b[43m(\u001b[49m\u001b[43mar\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_inverse\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_counts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m    275\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mequal_nan\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mequal_nan\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    276\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _unpack_tuple(ret)\n\u001b[1;32m    278\u001b[0m \u001b[38;5;66;03m# axis was specified and not None\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/numpy/lib/arraysetops.py:333\u001b[0m, in \u001b[0;36m_unique1d\u001b[0;34m(ar, return_index, return_inverse, return_counts, equal_nan)\u001b[0m\n\u001b[1;32m    330\u001b[0m optional_indices \u001b[38;5;241m=\u001b[39m return_index \u001b[38;5;129;01mor\u001b[39;00m return_inverse\n\u001b[1;32m    332\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m optional_indices:\n\u001b[0;32m--> 333\u001b[0m     perm \u001b[38;5;241m=\u001b[39m \u001b[43mar\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margsort\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkind\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmergesort\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mreturn_index\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mquicksort\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    334\u001b[0m     aux \u001b[38;5;241m=\u001b[39m ar[perm]\n\u001b[1;32m    335\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "N = 100\n",
    "rf_accuracies = []\n",
    "for i in range(N):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5, random_state=0)\n",
    "    clf = RandomForestClassifier(n_estimators=300)\n",
    "    clf.fit(X_train, y_train)\n",
    "    rf_accuracies.append(clf.score(X_test,y_test))\n",
    "\n",
    "print(\"%.3f\" %(100*(np.mean(rf_accuracies))),\"%\")\n",
    "print(\"%.3f\" %((np.std(rf_accuracies))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the graph Accuracy as a function of number of trees\n",
    "N = 50\n",
    "accuracy = []\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5, random_state=0)\n",
    "\n",
    "for i in range(N):\n",
    "    clf = RandomForestClassifier(n_estimators=(i+1)*10)\n",
    "    clf.fit(X_train, y_train)\n",
    "    accuracy.append(clf.score(X_test,y_test))\n",
    "    #print((i+1)*10, accuracy[i])\n",
    "\n",
    "plt.plot([10*(i+1) for i in range(50)], accuracy)\n",
    "plt.ylim((0.8,1))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Travail d'analyse\n",
    "- Comparer la performance entre l'arbre de décision et la forêt aléatoire en terme de taux de bonne classification et d'intervalle de confiance. \n",
    "\n",
    "- Analyser la courbe de performances obtenue en fonction du nombre d'estimateurs et étudier l'impact de la taille de l'ensemble d'apprentissage."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##   <font color='blue'> Etape 4 :  Classification avec Adaboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "# AdaBoost basé sur 200 arbres de décision\n",
    "clf = AdaBoostClassifier(estimator=tree.DecisionTreeClassifier(max_depth=1), n_estimators=500, learning_rate=0.1)\n",
    "clf.fit(X_train, y_train)\n",
    "accuracy = clf.score(X_test, y_test)\n",
    "print(\"Accuracy value:\",\"%.2f\" %(100*accuracy),\"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Travail d'analyse\n",
    " - Comparer les performance du Adaboost à la forêt aléatoire et à l'arbre de décision. \n",
    "   "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
